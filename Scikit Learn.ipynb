{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Python Package\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (loading Titanic dataset)\n",
    "data  = pd.read_csv('https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Transformer\n",
    "preprocessing = make_column_transformer(\n",
    "    (OneHotEncoder(), ['Pclass','Sex']),\n",
    "    (SimpleImputer(), ['Age']),\n",
    "    remainder='passthrough')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 0.0, 1.0, ..., 1, 0, 7.25],\n",
       "       [1.0, 0.0, 0.0, ..., 1, 0, 71.2833],\n",
       "       [0.0, 0.0, 1.0, ..., 0, 0, 7.925],\n",
       "       ...,\n",
       "       [0.0, 0.0, 1.0, ..., 1, 2, 23.45],\n",
       "       [1.0, 0.0, 0.0, ..., 0, 0, 30.0],\n",
       "       [0.0, 0.0, 1.0, ..., 0, 0, 7.75]], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit-Transform data with transformer\n",
    "preprocessing.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Python Package\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.compose import make_column_selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (loading Titanic dataset)\n",
    "data = pd.read_csv('https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Transformer\n",
    "preprocessing = make_column_transformer(\n",
    "    (OneHotEncoder(), make_column_selector(dtype_include='object')),\n",
    "    (SimpleImputer(), make_column_selector(dtype_include='int')),\n",
    "    remainder='drop'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<887x889 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1774 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Fit-Transform data with transformer\n",
    "preprocessing.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Python Package\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (loading Titanic dataset)\n",
    "data = pd.read_csv('https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set X and y\n",
    "X = data.drop('Survived',axis=1)\n",
    "y = data[['Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variables\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse=True)\n",
    "imputer = SimpleImputer(add_indicator=True, verbose=1)\n",
    "scaler = StandardScaler()\n",
    "clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Transformer\n",
    "preprocessing = make_column_transformer(\n",
    "(make_pipeline(imputer,scaler),['Age','Siblings/Spouses Aboard','Parents/Children Aboard','Fare'])\n",
    ",(ohe, ['Pclass','Sex','Name'])\n",
    ",remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score : 0.795222\n"
     ]
    }
   ],
   "source": [
    "# Make pipeline\n",
    "pipe = make_pipeline(preprocessing, clf)\n",
    "\n",
    "# Fit model\n",
    "pipe.fit(X_train, y_train.values.ravel())\n",
    "print(\"Best score : %f\" % pipe.score(X_test, y_test.values.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Python Package\n",
    "from sklearn.experimental import enable_iterative_imputer, enable_hist_gradient_boosting\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer, KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Python Package\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (loading Titanic dataset)\n",
    "data = pd.read_csv('https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv')\n",
    "# Set X and y\n",
    "X = data.drop('Survived',axis=1)\n",
    "y = data[['Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variables\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse=True)\n",
    "imputer = SimpleImputer(add_indicator=True, verbose=1)\n",
    "clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8287056433695168"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Transformer\n",
    "preprocessing = make_column_transformer(\n",
    "(make_pipeline(imputer),['Age','Siblings/Spouses Aboard','Parents/Children Aboard','Fare']),\n",
    "(ohe, ['Pclass','Sex','Name']),remainder='passthrough')\n",
    "# Make pipeline\n",
    "pipe = make_pipeline(preprocessing, clf)\n",
    "# Cross-validation\n",
    "cross_val_score(pipe, X, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python Package\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (loading Titanic dataset)\n",
    "data = pd.read_csv('https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv')\n",
    "# Set X and y\n",
    "X = data.drop('Survived',axis=1)\n",
    "y = data[['Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variables\n",
    "clf = LogisticRegression()\n",
    "ohe = OneHotEncoder()\n",
    "scaler = StandardScaler()\n",
    "imputer = SimpleImputer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7868977337649972\n"
     ]
    }
   ],
   "source": [
    "# Make Transformer\n",
    "preprocessing = make_column_transformer((make_pipeline(imputer,scaler),['Age','Siblings/Spouses Aboard','Parents/Children Aboard','Fare']),(ohe, ['Sex']),remainder='drop')\n",
    "# Make pipeline\n",
    "pipe = make_pipeline(preprocessing, clf)\n",
    "# Set params for Grid Search\n",
    "params = {}\n",
    "params['logisticregression__C'] = [0.1,0.2,0.3]\n",
    "params['logisticregression__max_iter'] = [200,500]\n",
    "# Run grid search\n",
    "grid = GridSearchCV(pipe, params, cv=5, scoring='accuracy')\n",
    "grid.fit(X,y.values.ravel())\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python Package\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Load data (loading Titanic dataset)\n",
    "data = pd.read_csv('https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv')\n",
    "# Set X and y\n",
    "X = data.drop('Survived',axis=1)\n",
    "y = data[['Survived']]\n",
    "# Split Train Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(531, 7)\n",
      "(178, 7)\n",
      "(178, 7)\n"
     ]
    }
   ],
   "source": [
    "# Import Python Package\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Load data (loading Titanic dataset)\n",
    "data = pd.read_csv('https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv')\n",
    "# Set X and y\n",
    "X = data.drop('Survived',axis=1)\n",
    "y = data[['Survived']]\n",
    "# Split Train, Val and Test \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25)\n",
    "# Print dataFrames size\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.0, 'mr. owen harris braund'],\n",
       "       [38.0, 'mrs. john bradley (florence briggs thayer) cumings'],\n",
       "       [26.0, 'miss. laina heikkinen'],\n",
       "       ...,\n",
       "       [7.0, 'miss. catherine helen johnston'],\n",
       "       [26.0, 'mr. karl howell behr'],\n",
       "       [32.0, 'mr. patrick dooley']], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Python Package\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "imputer = SimpleImputer()\n",
    "# Load data (loading Titanic dataset)\n",
    "data = pd.read_csv('https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv')\n",
    "# Set X and y\n",
    "X = data.drop('Survived',axis=1)\n",
    "y = data[['Survived']]\n",
    "# Write function\n",
    "def lower_letter(df):\n",
    "   return df.apply(lambda x : x.str.lower())\n",
    "# Convert function\n",
    "get_lower_letter = FunctionTransformer(lower_letter)\n",
    "# Make Pipeline\n",
    "preprocess = make_column_transformer((imputer, ['Age']),(get_lower_letter,['Name']),remainder='drop')\n",
    "preprocess.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
